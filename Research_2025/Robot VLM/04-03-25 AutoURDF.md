ðŸš€ Excited to share our new CVPR 2025 paper: AutoURDF!  
Manually designing robot models is tedious and time-consuming. We propose a fully unsupervised method to generate URDF files for unseen robots directly from time-series point cloud dataâ€”no motor signals or annotations needed.  
We validate AutoURDF on both synthetic and real-world robot scans.  
ðŸ› ï¸ Itâ€™s fully compatible with PyBullet and other simulators.  
This opens the door to scalable, automated robot modeling from purely visual data.  
ðŸŽ® Check out interactive demos and results on our Project Website:
 
Project: [https://lnkd.in/e2K5nGKy](https://lnkd.in/e2K5nGKy)  
ArXiv: [https://lnkd.in/eFTs9-d5](https://lnkd.in/eFTs9-d5)  
Paper: [https://lnkd.in/ezZ3FRjw](https://lnkd.in/ezZ3FRjw)
 
Huge thanks to my collaborators: Lechen Z., Kwansoo Lee, Jialong Ning, Judah Goldfeder, Hod Lipson.
 
Columbia Engineering, Columbia University Mechanical Engineering  
#CVPR #CVPR2025 #AI #robotics #digitaltwins #pointcloud #simulation #deeplearning #computervision #ColumbiaUniversity #CreativeMachinesLab
 \> From \<[https://www.linkedin.com/my-items/saved-posts/](https://www.linkedin.com/my-items/saved-posts/)\>