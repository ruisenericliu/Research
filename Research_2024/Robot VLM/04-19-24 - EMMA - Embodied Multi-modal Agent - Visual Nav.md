[https://arxiv.org/pdf/2311.16714](https://arxiv.org/pdf/2311.16714)
 
We're sharing our work on EMMA - the Embodied Multi-Modal Agent. It can understand and actively interact with its surroundings, without relying on hard-coded classifiers, object positions, or trajectories.
 
We're rapidly expanding EMMA's capabilities, adding features like pose estimation and tracking, along with quick fine-tuning throughout the stack for specific objects of interest. Plus, we're integrating generative models, such as those based on diffusion policies, for even more intuitive object interaction and robot behavior, all without needing to code - just using video and text instructions.
 
We're also on the lookout for applications in warehouses, assembly lines, and entertainment industries, where EMMA can handle real-world tasks, simplify robot interaction and commissioning processes. We're enhancing hardware support and ensuring EMMA is tough enough for any challenge.
 
Get in touch to learn more about EMMA!
 
EMMA is powered by [hashtag#ROS2](https://www.linkedin.com/feed/hashtag/?keywords=ros2&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7186703232222519296), [hashtag#IsaacSim](https://www.linkedin.com/feed/hashtag/?keywords=isaacsim&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7186703232222519296), and [hashtag#MoveIt](https://www.linkedin.com/feed/hashtag/?keywords=moveit&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7186703232222519296)!, which form the backbone of its operation. All models, including the [hashtag#LLM](https://www.linkedin.com/feed/hashtag/?keywords=llm&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7186703232222519296) and [hashtag#LVM](https://www.linkedin.com/feed/hashtag/?keywords=lvm&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7186703232222519296) for reasoning, [hashtag#CLIP](https://www.linkedin.com/feed/hashtag/?keywords=clip&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7186703232222519296)-based models for object detection, and those for voice, are interchangeable. In fact, we can benchmark various models to determine the best fit for different use cases.  
Remaining timeÂ 1:23  
1x  
EMMA - Embodied Multi-Modal Agent
 \> From \<[https://www.linkedin.com/feed/update/urn:li:activity:7186703232222519296/?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7186703232222519296%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29](https://www.linkedin.com/feed/update/urn:li:activity:7186703232222519296/?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7186703232222519296%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29)\>