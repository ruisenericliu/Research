We have developed a system capable of understanding its environment, utilizing OpenVLA and integrating it with a webcam connected to an NVIDIA Orin AGX 64. The system employs the Prism-DinoSigLip+7B model for its functionality.
 
The objective is to establish a chain-of-thought reasoning system, enabling a robotic arm to execute tasks such as object manipulation based on verbal commands.
 
However, the implementation faces challenges. The robotic arm in use is an older Dobot V1 model, lacking a URDF file and operating at a maximum baud rate of 9600, which results in slow response times.
 
Wish us luck!
 \> From \<[https://www.linkedin.com/my-items/saved-posts/](https://www.linkedin.com/my-items/saved-posts/)\>