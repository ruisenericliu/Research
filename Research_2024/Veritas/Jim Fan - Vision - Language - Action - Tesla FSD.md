Tesla FSD v13 will likely be grokking language tokens. What excites me the most about the Grok-1.5V announcement is the potential to solve edge cases in self-driving. Using language for "chain of thought" will help the car break down a complex scenario, reason with rules and counterfactuals, and explain its decisions. What Grok-1.5V can help is to lift pixel-\>action mapping to pixel-\>language-\>action instead.
 
With Tesla's highly mature data pipeline, it is not hard to label tons of edge cases with high-quality human explanation traces, and finetune Grok to be far better than GPT-4V and Gemini for multimodal FSD reasoning.
 
There were previous efforts on similar ideas, such as LINGO-1 (Wayve). But Tesla is spinning an unparalleled data flywheel that could scale far beyond.
 
Grok-1.5V: [https://lnkd.in/gq2QYmf2](https://lnkd.in/gq2QYmf2)  
LINGO-1: [https://lnkd.in/gvYCUQu4](https://lnkd.in/gvYCUQu4)  
NVIDIA Dolphins: [https://lnkd.in/gcckP87g](https://lnkd.in/gcckP87g)
 \> From \<[https://www.linkedin.com/feed/update/urn:li:activity:7185324872846192640/?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7185324872846192640%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29](https://www.linkedin.com/feed/update/urn:li:activity:7185324872846192640/?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7185324872846192640%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29)\>