## 12/30
- LiveTalk created [https://github.com/GAIR-NLP/LiveTalk](https://github.com/GAIR-NLP/LiveTalk)

## 12/29
- UI Tars Desktop: [https://github.com/bytedance/UI-TARS-desktop](https://github.com/bytedance/UI-TARS-desktop)
- > Alibaba dropped a long context Qwen, ASR model, Qwen-Image-Layered
- > NVIDIA released game playing agent NitroGen, Nemotron Cascade and datasets
- > Google DeepMind dropped Gemma Scope 2, FunctionGemma, datasets
- find even more releases by Meta, Xiaomi, Minimax and others here! [https://lnkd.in/gNezj32b](https://lnkd.in/gNezj32b)

## 12/21
- Gemini Interactions API now available for code assist
- Anthropic launches Bloom, an open-source framework to speed up frontier-model behavioral evaluations from weeks to days

## 12/19
- Mistral OCR 3 [https://mistral.ai/news/mistral-ocr-3?utm_source=alphasignal&utm_campaign=2025-12-19&lid=sY3RsoPkN38aqaA1](https://mistral.ai/news/mistral-ocr-3?utm_source=alphasignal&utm_campaign=2025-12-19&lid=sY3RsoPkN38aqaA1)
- FunctionGemma

## 12/17
- Gemini 3 Flash released: [https://blog.google/products/gemini/gemini-3-flash/](https://blog.google/products/gemini/gemini-3-flash/)
    - 50 cents per 1M input tokens
- GPT-5.2â€™s gains in computational efficiency are stark. One year ago, achieving 88 percent on ARC-AGI-1 cost roughly $4,500 per task. GPT-5.2 Pro achieves 90.5 percent at around $12 per task, roughly 390 times less.
- Weâ€™re thinking: Technical approaches that arenâ€™t economically feasible today, say running hundreds of reasoning attempts per problem or deploying thousands of reasoning-heavy agents, are on track to become surprisingly affordable within a few years.

## 12/16
- Molmo 2 out
- Nemotron 3 out

## 12/15
- Gemini Flash Native Audio: [https://blog.google/products/gemini/gemini-audio-model-updates/?utm_source=alphasignal&utm_campaign=2025-12-15&lid=7GE4GYjltODxXJXi](https://blog.google/products/gemini/gemini-audio-model-updates/?utm_source=alphasignal&utm_campaign=2025-12-15&lid=7GE4GYjltODxXJXi)

## 12/14
- Llama-scan : CLI tool that uses local multimodal models via Ollama to transcribe your PDFs.

## 12/12
- Olmo 3 out

## 12/11
- GPT 5.2 out
    - RAG architecture replaced by Agentic Search?

## 12/5
- Gemini Deep Think Comes out

## 12/1
- Qwen VL 3
- SDPA output gating
- DeepSeek 3.2
- Bytedance Depth Anything 3
- Nano Banana 2

## 11/25
- Google Antigravity - coder

## 11/8
- Gemini 3 comes out
- Kimi-K2 Thinking beats GPT 5

## 11/6
- Futurehouse just announced the launch of its commercial spinout **Edison Scientific**, debuting an autonomous AI research system called **Kosmos**, a tool built to handle full-scale scientific discovery.

## 11/5
- **Results:** MiniMax-M2 achieved 61 on independent evaluator Artificial Analysisâ€™ Intelligence Index (a weighted average of benchmark performance in mathematics, science, reasoning, and coding), a new high for open weights models, ahead of DeepSeek-V3.2 (57 points) and Kimi K2 (50 points). It trails proprietary models GPT-5 with thinking enabled (69 points) and Claude Sonnet 4.5 (63 points). Beyond that, it excelled in coding and agentic tasks but proved notably verbose. It consumed 120 million tokens to complete Artificial Analysis evaluations, tied for highest with Grok 4.

## 10/30
- Cursor major upgrade
- FastVLM from Apple

## 10/23
- Ling 1T:
    - **Input/output:** Text in (up to 128,000 tokens), text out (up to 32,000 tokens)
    - **Architecture:** Mixture-of-Experts (MoE) transformer, 1 trillion parameters, 50 billion parameters active per token
    - **Performance:** Outperformed leading non-reasoning models in 22 of 31 benchmark tests of reasoning, math, coding, general knowledge, and writing.
    - **Availability:** Weights free to download from [HuggingFace](https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWQh9n19rhFMW2Q6CpG8VqS7_W97gBTk5DZJqFN8fXWBx3qgz0W7lCdLW6lZ3ltW6p4dRX6VRgT1W7NQl0l25xCgdW6xhn638npY6BW3ZNTBF8Fcpl7W3KsBSH6YMMQ4W2Rnyls1rCG1tW2G5cdc3m61rwW4klHgL5RJjcXN38wQwBjxHXLW62Vnpw4KL0-3W35wm8d3NxR1MW2HWy0t2w0d75W5ykJH66kLFYfW8zP-892SB6YCW36x-pN8-l1PLW8CmBPK3Mw9-kVjlXgf43qp8xVt_wps3P8hHBW67MsVT36LGWGW2XgLrh8djpkLW3sCdYD3sZsj2W12jhqy4B3y1yVgcXw02kbRWlW9jN-806T6h2Yf68Rx0W04) and [ModelScope](https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWQh9n19rhFMW2Q6CpG8VqS7_W97gBTk5DZJqFN8fXWBx3qgz0W7lCdLW6lZ3pYW8d4JNJ15hkyVW5bJ5nL3CFKsNW42zq1q8lvZ5gW3QKmj77w7dNkV_3c431C4tDwW7ms4M88tQ5XcN6j22pWNkxlPW25038n6-ZJmWW8nlDjr4N97dcW6bxStg8kK10xW6_Tgw66Qn365W5xqmZ9413YTvW53kszF4jXkpkW49jH8C5CbPK4W99Lk5V5PKW9xW9cq_VZ1Xpy5DW4Bw1qM7R2SsbW7mMx2Z6cfVPMVfPj0w8pJ9ppW7Gbc3P5x1xWRW3n82N06cV2SDW2SkjsQ31JDSwW4gzxcS8fBn7HW56h3yC49l9hcf1lScg804) for commercial and noncommercial uses under the MIT license, API $0.56/$0.112/$2.24 per million input/cached/output tokens via [zenmux.ai](https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWQh9n19rhFMW2Q6CpG8VqS7_W97gBTk5DZJqFN8fXWBx3qgz0W7lCdLW6lZ3nXVTZwS47XdFLTW3WdRH6774jD4W2X7th37V69Y5W7b1lCQ2JyvQfW97g5S373H2lLW1LnJLr71tLxfW7qPV2J5tRW_kW1GgJ5C4ldjv-N1gFKZJrDmqWW2Ns20051t9wJVs9Dnf4hDgwMN85gYtXQHQqSW6jcp1R7lhrKmVJGmqy7_vT7RW8zmg3v10f3YmN3MLK2NttRDhW2RRJ-r4LJT44W8nyThm1nrnlgW5bh-gT1QmydfW7jB_Qx4-CLr3W6vd-bW3zwCs9W26Kh3034lQmjW5jXzc28QK4YzN3qhVQ4wKD0Qf9bhm5z04)
    - **Undisclosed:** Training data, specific training methods

## 10/16
- Qwen3 VL 4B and 8B out

## 10/06
- RF detr

## 9/30
- Tinker released [https://app.alphasignal.ai/tc?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkZXN0aW5hdGlvbiI6InJ1aXNlbmVyaWNsaXVAZ21haWwuY29tIiwiYXNfY2FtcGFpZ25faWQiOiJmZGUyMzY5ZmVkN2M2Mjc1IiwibGlua19pZCI6InFMT1BveUgwYTFJQWVSMVUifQ.BB6vzn03X4gtmbtrRwfH9TjIxQMfliy2r0UsS4FO_mc](https://app.alphasignal.ai/tc?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkZXN0aW5hdGlvbiI6InJ1aXNlbmVyaWNsaXVAZ21haWwuY29tIiwiYXNfY2FtcGFpZ25faWQiOiJmZGUyMzY5ZmVkN2M2Mjc1IiwibGlua19pZCI6InFMT1BveUgwYTFJQWVSMVUifQ.BB6vzn03X4gtmbtrRwfH9TjIxQMfliy2r0UsS4FO_mc)
- Claude Sonnet 4.5

## 09/15
- [Google introduces VaultGemma, an open-weight model ensuring data protection](https://link.alphasignal.ai/PFGVYS)
- Differential privacy is a mathematical framework that adds noise during training so that individual training examples cannot be extracted from the model. It ensures that model outputs reveal patterns about the dataset as a whole, while protecting sensitive details about any single data point.

## 09/02
- Microsoft debuts open-source text-to-speech model, outperforming Gemini 2.5 and Eleven v3 - VibeVoice
- [Microsoft ships its first in-house AI models, covering speech and text](https://link.alphasignal.ai/bDSIi4)
- Apple introduces FastVLM

## 08/25
- **How it works:** Magic Cue takes advantage of an updated version of [Gemini Nano](https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MWVCwjf6MFnMvQ3H7nxCdbW8SvcRS5BLH6gN2x86xg5nR3bW50kH_H6lZ3n9N6VzRHvLMfV5W70yNz0774TMDW70jvsb1pqdWnW9kCZgv2DY3qDW6Wzvq73d73k2W2kspjJ91Ygd9N4r0yHy1jlgqW4zT9nM6nYfLLW9fZ62c3l4ZbSW1thBZ91z0gVpW3N5-HT3FP14VW4zM_wg5n5LZPW7r5TLV7DmFSfW3GcSvm39hWTZN3W0TlWQkSFVW48NN1w8LZ49RVLy8th9b1-tpN7wdMYhGwy-8W7mxqPK4P9t0gW6B8Yq92nFrH_W6bJP_p3NlPMtW68SPYZ2W93CcV4-Hzg2gQw2-W8SzPpB2CN9xpW2BFfBx7WvY0bW35DJvN6tGqWqW1M7Nf02cCHTrW41MJ715tmfvLW4yRK6h5Jq8DDW7cqYJ14t51WNW4WsGV027GG63W4H7Dv445dL7Sf6B31mF04) and runs on the Pixel 10â€™s newly upgraded [Tensor G5](https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MWVCwjf6MFnMvQ3H7nxCdbW8SvcRS5BLH6gN2x86yM3qgz0W7Y8-PT6lZ3pJV7T5243-ZKGbW7zJgDy2GM--7VKZ5LS5hhFK0N5BtZxL1K1MYW3SFpr56VG-_gVThG-R8HVdjRVrFH-45Z6T2RW8qtD1J89V8PqW77QFfl57L3lxW5mcY687LsN8kV64_RM3nf84dW7dX-mZ8YRWqTN7pgwNSzSJdmN190Kv31RbmDW6p08w71dzbdPN23HbPv5cLFxW8tgm1K3cPc46Vmn2Zc3fxmXRW6XsPQ97_x_ncW18bKrq2PC-4jN4QG24ZYns88W3SRSlf8cDj2zW2BHl_g13jSSXW1HlfZW4J_nBdW8Tw5cr2m4TYdMbZ-1xHZv7Gf30ZDhb04) AI processor. The system tracks user behavior and provides relevant information proactively.

## 08/15
- DinoV3
- Imagen 4
- Skild Brain

## 08/10
- Prophet Arena
- [https://www.prophetarena.co/blog/welcome](https://www.prophetarena.co/blog/welcome)

## 08/07
- GPT 5 comes out

## 08/05
- [https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/](https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/)

## 08/02
- AlphaEarth out
- Gemini 2.5 DeepThink out

## 08/01
- olmOCR v0.2.1From out for fast(er) OCR on OCR-bench.

## 07/30
- [Warp's AI coding agent leaps ahead of Claude Code, hits #1 on Terminal-Bench](https://cc554gl0.r.us-east-2.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2FAldwBy/1/010f01985dc3fe4a-c2f8079a-6b43-4cfe-a403-7fe00eb19516-000000/7KCCVLcAyRYijDlwi_qrUBe-gvA=222)
    - That said, we have a real advantage on the UI side compared to other tools in the space like [Claude Code](https://thenewstack.io/claude-opus-4-with-claude-code-a-developer-walkthrough/), [Codex CLI](https://thenewstack.io/testing-openai-codex-and-comparing-it-to-claude-code/), or [Gemini CLI](https://thenewstack.io/gemini-cli-googles-challenge-to-ai-terminal-apps-like-warp/). Those products canâ€™t build a WYSWYG editor at all â€” let alone a great code review experience.
    - > From <https://thenewstack.io/qa-how-warp-2-0-compares-to-claude-code-and-gemini-cli/>
- [Alibaba Qwen releases updated Qwen3-30B-A3B](https://cc554gl0.r.us-east-2.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2FxiFi4r/1/010f01985dc3fe4a-c2f8079a-6b43-4cfe-a403-7fe00eb19516-000000/D_4dsAF2RVTrW4zm9Fb9PvRQsyc=222)

## 07/22
- Gemini 2.5 offers conversational segmentation
- Qwen3 Coder out

## 07/18
- [OpenAI launches ChatGPT Agent, automates tasks with app access](https://cc554gl0.r.us-east-2.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2F7n4MCC/1/010f01981e087bd4-9834bc85-0a60-4410-8be7-e53c32aab7fa-000000/10giesVYxRy-On4Xi6SXMaE3Du0=220)
- [Anthropic announces a Claude tool for financial analysis](https://cc554gl0.r.us-east-2.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2Ffj9m7O/1/010f01981e087bd4-9834bc85-0a60-4410-8be7-e53c32aab7fa-000000/f-hptg9hAkZJW4E3xuH6ew5RAr4=220)
- [OpenAI, DeepMind researchers propose Chain-of-Thought traces as safety tool](https://cc554gl0.r.us-east-2.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2FwMmkJc/1/010f01981e087bd4-9834bc85-0a60-4410-8be7-e53c32aab7fa-000000/d9Mb426oSo9NZdBzgYmMEz6cAr0=220)

## 07/15
- Kimi-K2 by Moonshot AI

## 07/12
- Grok-4 with agent swarm
- Deepmind hires windsurf

## 07/04
- Gemma3n (Text, Audio, Vision) - Fine-Tuning
    - Blog: [https://lnkd.in/ejsHieKD](https://lnkd.in/ejsHieKD)
    - Gemma Recipes: [https://lnkd.in/eN9wdDy5](https://lnkd.in/eN9wdDy5)
    - (4B and 2B)

## 06/24
- [ElevenLabs introduces Conversational AI 2.0](https://link.alphasignal.ai/lpzoYI), enabling AI agents to handle multiple languages and personas mid-call.
- **â€º** [ElevenLabs unveils 11.a voice assistant](https://cc554gl0.r.us-east-2.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2Fq79NKP/1/010f0197a4dd2c31-225521b1-40e6-4c5f-8837-151c41e554de-000000/LwnZ0wJJ7Ppxs_sABWPRWtFIYt0=216). Lets you create tasks and summarizes your schedule.
- [11.ai](http://11.ai/) supports both voice and text in the same session and detects language automatically
    - Plan your day and write tasks to Notion or Linear
    - Search Slack messages or emails and summarize key updates
    - Create and manage Linear tickets via voice
    - Research topics using Perplexity and outline findings
- **System Architecture**
    - Runs on ElevenLabs' Conversational AI platform
    - Detects almost 70+ languages automatically for multilingual interaction
    - Uses RAG for context-aware responses
    - Maintains conversational flow across multi-step interactions
- Poutine:
    - Our 3 B-parameter VLM Poutine scored 7.99 RFS on the official test setâ€”comfortably ahead of every other entry (see figure).
    - 2025 Waymo Vision-based End-to-End Driving Challenge!

## 06/16
- Anthropic system detailed: [https://www.anthropic.com/engineering/built-multi-agent-research-system](https://www.anthropic.com/engineering/built-multi-agent-research-system)
- [Building a fully local "deep researcher" with DeepSeek-R1](https://www.youtube.com/watch?v=sGUjmyfof4Q)

## 06/14
- HailLuo beats Veo3:
    - Link: [https://hailuoai.video/](https://hailuoai.video/)
    - Video gen leaderboard: [https://lnkd.in/gJ57RTKb](https://lnkd.in/gJ57RTKb)

## 06/10
- Apple 3B Foundational: [https://developer.apple.com/videos/play/wwdc2025/286/](https://developer.apple.com/videos/play/wwdc2025/286/)

## 06/01
- Chatterbox TTS by Resemble AI - Zero shot voice cloning, Apache 2.0 licensed ðŸ¤¯

## 05/29
- â€º Mistral releases Codesral Embed beating OpenAI and Cohere in code retrieval accuracy.

## 05/28
- Gemma3n
- ByteDance debuts BAGEL, a 7B open-source model that allows you to edit multiple images at once.
- Lovable, a Cursor competitor says its new Claude 4 integration will reduce bugs by 25%.
- Gemini 2.5 Technical Report:
    - New Gemini 2.5 Technical Report ðŸ§µ
    - Gemini 2.5 uses a sparse Mixture-of-Experts (MoE) architecture with native multimodality. Its diverse pre-training dataset includes web docs, code, and media, with a knowledge cutoff of January 2025 and improved data quality methods. Table 1 details the full model family capabilities.
    - A key advance in Gemini 2.5 is its "Thinking" capability, allowing models to use more inference-time compute. This boosts reasoning across all domains and significantly improves math and coding abilities. The AIME 2025 score jumped from 29.7% with 2.0 Flash to 72.0% with 2.5 Flash.
    - Gemini 2.5 expands video understanding and can now process up to 3 hours of video content. This is due to improved audio-visual and temporal understanding capabilities, which unlock new interactive applications. 2.5 Pro precisely recalled a 1-second event from a 46-minute video.
    - The model's agentic capabilities were demonstrated in the "Gemini Plays PokÃ©mon" experiment. Gemini Maintained long-horizon goals for over 800 hours and succesfully completed the entire game. A 2nd autonomous run finished in nearly half the time.
    - Gemini 2.5 is the first family trained on TPUv5p benefiting from new fault tolerance for stable training.
    - Full Report: [https://lnkd.in/dXF5AiRi](https://lnkd.in/dXF5AiRi)

## 05/15
- Google debuts AlphaEvolve, AlphaEvolve generates and refines algorithms through an evolutionary framework.
    - Found a 4x4 matrix multiplication algorithm using 48 scalar multiplications
    - Solved over 50 open math problems, including analysis, combinatorics, and number theory
    - Rediscovered the best-known solutions in 75% of cases
    - Improved upon known solutions in 20% of cases
- ByteDance takes the lead on vision models! Small (~21B) Seed1.5 beats behemoths like Claude ðŸ”¥
    - This model is, like many other Vision Language Models (VLM), a coupling of a vision encoder and an LLM part : it has 532M-parameter vision encoder coupled with a 20B-parameter Mixture-of-Experts (MoE) LLM.
    - => It's quite small, yet it reaches state-of-the-art results on most vision benchmarks, including GUI tasks, OCR, 3D localization.
    - > From <https://www.linkedin.com/my-items/saved-posts/>

## 05/14
- ByteDance open-sources DeerFlow to automate research workflows with code execution and TTS support.
    - It builds on LangGraph for multi-agent task orchestration, allowing structured, automated workflows.
    - **Text-to-Speech (TTS) Support**
    - It includes TTS features using volcengine for converting text to high-quality speech.
- **Whatâ€™s new:** Microsoft released Phi-4-reasoning, Phi-4-reasoning-plus and Phi-4-mini-reasoning along with lessons learned in building the models.
- **Whatâ€™s new:** A team at the model platform Together.AI and Agentica, an open-source project devoted to reinforcement learning (RL), released DeepCoder-14B-Preview. The release includes weights, code, dataset, training logs, and data optimizations under an MIT license that allows noncommercial and commercial uses
    - DeepCoder-14B-Previewâ€™s optimizations reduced this complexity, shrinking RL training from months to weeks. Those optimizations are built into Verl-pipeline, an open source RL library from Together.AI and Agentica, giving developers a powerful tool for model training.
    - > From <https://mail.google.com/mail/u/0/#inbox/FMfcgzQbfLRLrNVvqKrQvXSGPfZKSgrR>

## 05/12
- [Google adds two models to Gemini](https://link.alphasignal.ai/mzzxix), enabling 6-hour video analysis and code generation from long video input
- Tencent unveils HunyuanCustom, rivaling closed-source models with high-fidelity, multi-subject, and audio-synced video generation.
- Hugging Face releases Open Computer Agent, challenging OpenAI Operator with open models and virtual desktop.

## 05/10
- New sota open-source depth estimation: Marigold IID ðŸŒ¼
- > normal maps, depth maps of scenes & faces
- > get albedo (true color) and BRDF (texture) maps of scenes, they even release a depth-to-3D printer format demo ðŸ˜®
- links to all models and demos in comments ðŸ¤—

## 05/7
- Qwen 3

## 05/06
- [NVIDIA unveils an open-source speech to text model](https://link.alphasignal.ai/HbMepR) with song lyric transcription, timestamp accuracy, and 24-minute audio context.
- Arcana, Rimeâ€™s new TTS model makes AI speech sound indistinguishably human. Hear it live now.
    - < 100 ms firstâ€‘token latency onâ€‘prem (subâ€‘200 ms cloud) â€” silence disappears.
    - (doesn't seem to work)
    - Compare in a moment to Elevelabs!
- Qwen-Agent: Build multimodal, tool-using agents with code execution, RAG, planning, and memory using Qwen models.
- graphiti: framework for real-time, bi-temporal knowledge graphs that support dynamic AI agent memory, and structured reasoning.

## 05/01
- New foundation model on image and video captioning just dropped by NVIDIA AI ðŸ”¥
- Describe Anything Model (DAM) is a 3B vision language model to generate detailed captions with localized references ðŸ˜®
- Most of the vision LMs focus on image as a whole, lacking localized references in captions, and not taking in visual prompts (points, boxes, drawings around objects)
- DAM addresses this on two levels: new vision backbone that takes in focal crops and the image itself, and a large scale dataset ðŸ‘€
- They generate a dataset by extending existing segmentation and referring expression generation datasets like REFCOCO, by passing in the images and classes to VLMs and generating captions.
- Lastly, they also release a new benchmark again with self-supervision, they use an LLM to evaluate the detailed captions focusing on localization ðŸ‘
- Pretty WILD - SoTA open source TTS model that beats ElevenLabs/ Sesame - Dia 1.6B - Apache 2.0 licensed! ðŸ”¥
    - > Ultra realistic voice synthesis
    - > Capable of producing non-verbal sounds - coughing, laughing ðŸ’¥
    - > Zero shot Voice Cloning
    - > Real-time TTS synthesis
    - > Can run on your MacBook
    - > Trending #2 on Hugging Face
    - Weights on the Hub and code on GitHub!

## 04/30
- **Weâ€™re thinking:** GPT Image 1 is part of an exciting trend toward unification of multimodal architectures. Researchers have progressed from text-in, text-out to text/images-in, text-out and increasingly text/images/audio-in, text/images/audio-out. This paints a beautiful picture of where multimodal models can go!

## 04/21
- Gemma 3 comes out, quantization aware (can run on 3090)

## 04/18
- [Microsoft introduces real-time UI agents](https://link.alphasignal.ai/zZVz5f) in Copilot Studio to automate desktop and web workflows without APIs.
- [Google adds Veo 2](https://link.alphasignal.ai/FVSha9) to Gemini API, AI Studio, and mobile app for text-to-video generation.
- [Meta unveils Perception Language Model](https://link.alphasignal.ai/776tec): open 8B vision-language model trained without distillation for video understanding.
- [Ai2 launches DataDecide](https://link.alphasignal.ai/2EBVO7), a public suite of 30K models to predict best pretraining data efficiently.
- [ByteDance announces a video foundation model](https://link.alphasignal.ai/jKCRxL) enabling fine-grained storytelling, camera control, and CGI-tuned realism.

## 04/11
- [Google unveils open-source Firebase Studio](https://link.alphasignal.ai/0tlXWN): Build full-stack apps from prompts in seconds.
- [Integrate real-time speech-to-text with sub-second latency](https://link.alphasignal.ai/UMkJ6q) and 90%+ accuracy to your voice stack today.

## 04/05
- Llama 4 release (3 versions, MOE)

## 04/03
- MoshiVis (Voice2Voice)

## 03/26
- Gemini Pro

## 03/25
- Sesame AI - CSM-1B Voice agent

## 03/21
- Gemini 2.5 Pro - does decent at coding

## 03/17
- Aya Vision (multilingual)
- Ernie by Baidu [https://link.alphasignal.ai/j6rX6f](https://link.alphasignal.ai/j6rX6f)

## 03/12
- Gemma 3

## 03/06
- Mistral OCR model
- qwq 32B, manus: [https://huggingface.co/blog/LLMhacker/manus-ai-best-ai-agent](https://huggingface.co/blog/LLMhacker/manus-ai-best-ai-agent)

## 02/28
- Phi 4

## 02/27
- Gemini Assistant

## 02/25
- Claude 3.7

## 02/21
- Helix, Siglip2

## 02/15
- zonos tts

## 02/10
- EleGNT [https://machinelearning.apple.com/research/elegnt-expressive-functional-movement](https://machinelearning.apple.com/research/elegnt-expressive-functional-movement)

## 01/31
- Tulu 405B, Mistra Small 3

## 01/30
- Qwen 2.5Max
- Qwen2.5 (old) Technical Report [https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_qwen-25-technical-report-released-what-activity-7275808991245467648-acZF?utm_source=share&utm_medium=member_ios](https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_qwen-25-technical-report-released-what-activity-7275808991245467648-acZF?utm_source=share&utm_medium=member_ios)

## 01/21
- Hunyan 3D 2.0
- Deepseek R1 paper released
- Also DeepSeek 'cheated', it was trained on model output and thinks it is GPT-4, you cannot use output to develop models that compete with OpenAI( [https://openai.com/policies/row-terms-of-use/](https://openai.com/policies/row-terms-of-use/)). Stanford Alpaca ( [https://crfm.stanford.edu/2023/03/13/alpaca.html](https://crfm.stanford.edu/2023/03/13/alpaca.html)) was trained in 3 hrs on $600 of compute using data from model output, rather than a mess of datasets. Resulting Alpaca performance matched those of Llama and OpenAI. When training responses are consistent, the models learn more efficiently. "SCAR: Efficient Instruction-Tuning for Large Language Models via Style Consistency-Aware Response Ranking" [https://arxiv.org/abs/2406.10882](https://arxiv.org/abs/2406.10882).

## 01/16
- Apache 2.0 8B SJT

## 01/13
- [https://novasky-ai.github.io/posts/sky-t1/](https://novasky-ai.github.io/posts/sky-t1/)
- UC Berkeleyâ€™s NovaSky team releases Sky-T1-32B-Preview, an open-source reasoning model that matches OpenAIâ€™s o1-preview on key benchmarks. The model offers advanced reasoning in math and coding, achieving high performance with a training cost below $450.
    - We use our training data to fine tune Qwen2.5-32B-Instruct, an open source model without reasoning capabilities. The model is trained with 3 epochs, learning rate 1e-5 and batch size 96. The model training finishes in 19 hours on 8 H100 with DeepSpeed Zero-3 offload (~ $450 according to Lambda Cloud pricing). We use Llama-Factory to perform training.

## 01/11
- 350MB is all you need to get near SoTA TTS! ðŸ¤¯
- Meet Kokoro 82M - Apache 2.0 licensed, Text to Speech model, trained on < 100 hours of aud

## 01/09
- ByteDance SA2VA (VLM)
    - Built on Qwen2VL|InternVL and SAM2) - [https://github.com/magic-research/Sa2VA](https://github.com/magic-research/Sa2VA)
    - Qwen2VL: [https://arxiv.org/abs/2409.12191](https://arxiv.org/abs/2409.12191)
    - InternVL: [https://arxiv.org/abs/2312.14238](https://arxiv.org/abs/2312.14238)
- Moondream 2B

## 01/08/2025
- Phi 4 (LLM)

## 12/19/2024
- DistillBert [https://huggingface.co/blog/modernbert](https://huggingface.co/blog/modernbert)

---

### No Date
- Homebrew Labs released Ichigo, an opensource Llama 3 based advanced voice mode
    - Here's what makes it different:
    - **Direct Voice Processing**
        - â†³ No separate speech-to-text needed
        - â†³ No text-to-speech conversion
        - â†³ Everything happens in one model
    - **Multilingual Support**
        - â†³ Trained on diverse language data
        - â†³ Maintains 63.79 MMLU score
        - â†³ Handles accents naturally
    - **Smart Rejection**
        - â†³ Knows when audio is unclear
        - â†³ Won't guess at garbled speech
        - â†³ Actually tells you it can't understand
    - **Multi-turn Conversations**
        - â†³ Remembers context
        - â†³ Maintains natural flow
        - â†³ Learns from previous exchanges