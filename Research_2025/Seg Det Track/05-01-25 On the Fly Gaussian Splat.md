With our image-based rendering research over the 20 years we overcame the rigidity of the multi-view stereo to allow truly realistic novel view synthesis with 3D Gaussian splatting. But the cost of camera calibration was still a major obstacle, especially for large scenes. We have made a significant step forward with our ACM Trans. on Graphics paper, to be presented at SIGGRAPH 2025: "On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images" where we jointly optimize cameras poses and 3D Gaussian Splats so fast that a good quality reconstruction is ready at the time you finish taking pictures. For more see here:
 
[https://lnkd.in/dyUbHk64](https://lnkd.in/dyUbHk64)
 
This is the work with the talented members of our group, starting researcher AndrÃ©as Meuleman and Ph.D. student/research engineer Alexandre Lanvin and Ishaan Shah, in collaboration with Bernhard Kerbl from TU Wien.
 
See also:
 
[https://lnkd.in/dut9fU8E](https://lnkd.in/dut9fU8E)
 
And for an demo of real-time capture:
 
[https://lnkd.in/dBb3E8h9](https://lnkd.in/dBb3E8h9)
 
This work was funded by the European Research Council, Advanced Grant NERPHYS [https://lnkd.in/djE6CZTm](https://lnkd.in/djE6CZTm)
 \> From \<[https://www.linkedin.com/my-items/saved-posts/](https://www.linkedin.com/my-items/saved-posts/)\>