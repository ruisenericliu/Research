![Number of Al publications by field of study exclud...](Exported%20image%2020260222202644-0.png) ![Granted Al patents of world total by region, 20102...](Exported%20image%2020260222202645-1.png)  
![Training compute of notable machine learning model...](Exported%20image%2020260222202646-2.png)

For instance, the researchers estimate that  
computer scientists could deplete the stock of  
high-quality language data by 2024, exhaust low-  
quality language data within two decades, and  
use up image data by the late 2030s to mid-2040s  
(Figure 1.3.8).
 ![Foundation models by access type, 201923 Source Bo...](Exported%20image%2020260222202649-3.png) ![Number of foundation models by organization, Sourc...](Exported%20image%2020260222202650-4.png)

Training Cost:  
OpenAI’s CEO, Sam Altman, mentioned that the training cost for GPT-4 was over  
$100 million.  
For example, in 2017, the original Transformer model, which introduced the  
architecture that underpins virtually every modern LLM, cost around $900 to train.  
Fast-forward to 2023, and training costs for OpenAI’s GPT-4 and Google’s Gemini Ultra are estimated to be around $78 million and $191 million, respectively.

![Estimated training cost of select Al models, 20162...](Exported%20image%2020260222202651-5.png)

Since 2011, the number of AI-related GitHub projects has seen a consistent  
increase, growing from 845 in 2011 to approximately  
1.8 million in 2023.13 Notably, there was a sharp 59.3%  
rise in the total number of GitHub AI projects in the  
last year alone.