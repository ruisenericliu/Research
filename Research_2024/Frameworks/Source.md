[https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming](https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming)  
[https://medium.com/correll-lab/grow-your-own-expert-for-free-with-langchain-local-llava-rag-add630abbe6f](https://medium.com/correll-lab/grow-your-own-expert-for-free-with-langchain-local-llava-rag-add630abbe6f)
 
[https://agibot-world.com/](https://agibot-world.com/)
 
â˜€ï¸New paper!
 
Generative AI agents are powerful but complexâ€”how do we design them for transparency and human control? ðŸ¤–âœ¨
 
At the heart of this challenge is establishing common ground, a concept from human communication. Our new paper identifies 12 key challenges in improving common ground between humans and AI agents.
 
Some challenges focus on how agents can convey necessary information to help users form accurate mental models. Others address enabling users to express their goals, preferences, and constraints to guide agent behavior. We also focus on overarching issues like avoiding inconsistencies and reducing user burden.
 
Why does this matter?  
Without proper grounding, we risk safety failures, loss of user control, and ineffective collaboration. Trust and transparency in AI systems depend on addressing these challenges. We're calling on researchers and practitioners to prioritize these issues.
 
ðŸŒŸ Let's work together towards multidisciplinary solutions that enhance transparency, control, and trust in AI agents!
 
ðŸ“„ Read more at [https://lnkd.in/gwTB-T4G](https://lnkd.in/gwTB-T4G)
 
This is joint work with my wonderful colleagues [Jenn Wortman Vaughan](https://www.linkedin.com/in/jennifer-wortman-vaughan/) [Daniel Weld](https://www.linkedin.com/in/prof-daniel-weld/) [Saleema Amershi](https://www.linkedin.com/in/saleema-amershi/) [Eric Horvitz](https://www.linkedin.com/in/erichorvitz/) [Adam Fourney](https://www.linkedin.com/in/adamfourney/) [Hussein Mozannar](https://www.linkedin.com/in/husseinmozannar/) [Victor Dibia, PhD](https://www.linkedin.com/in/dibiavictor/)
 \> From \<[https://www.linkedin.com/feed/update/urn:li:activity:7269645555796963328/](https://www.linkedin.com/feed/update/urn:li:activity:7269645555796963328/)\>     

[Spot Watches Its Step | Boston Dynamics](https://youtu.be/YD9EaS3VRbc)
 
Tiny LLM  
[https://www.seeedstudio.com/blog/2024/05/03/tinyml-local-llms-a-trendy-architecture-for-efficient-and-affordable-edge-ai/](https://www.seeedstudio.com/blog/2024/05/03/tinyml-local-llms-a-trendy-architecture-for-efficient-and-affordable-edge-ai/)
 
Andrej Karpathy writes a [viral tweet](https://y1mnw3w8.r.us-east-1.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2FpWOFur/1/010001918ffe5ca6-c1c59075-48c3-4dcb-9487-8b1eb4bf2756-000000/goYJ0AZY6jgbvHOSorJqRQLdLpc=388) about how Cursor IDE with Claude Sonnet 3.5 is replacing GitHub Copilot for him.  
(Cursor + Sonnet 3.5)
 
[https://www.cursor.com/blog/problems-2023](https://www.cursor.com/blog/problems-2023)  
[https://docs.github.com/en/copilot/using-github-copilot/using-claude-sonnet-in-github-copilot](https://docs.github.com/en/copilot/using-github-copilot/using-claude-sonnet-in-github-copilot)  
[https://cloud.google.com/blog/products/ai-machine-learning/gemini-models-on-github-copilot?utm_source=linkedin&utm_medium=unpaidsoc&utm_campaign=fy24q4-googlecloud-blog-ai-in_feed-no-brand-global&utm_content=-&utm_term=-&linkId=11512100](https://cloud.google.com/blog/products/ai-machine-learning/gemini-models-on-github-copilot?utm_source=linkedin&utm_medium=unpaidsoc&utm_campaign=fy24q4-googlecloud-blog-ai-in_feed-no-brand-global&utm_content=-&utm_term=-&linkId=11512100)  
[https://www.linkedin.com/posts/perplexity-ai_were-excited-to-partner-with-github-with-activity-7257084437740335107-_GZI?utm_source=share&utm_medium=member_desktop](https://www.linkedin.com/posts/perplexity-ai_were-excited-to-partner-with-github-with-activity-7257084437740335107-_GZI?utm_source=share&utm_medium=member_desktop)
 
I'd like to introduce what I've been working on the last few months at [Hello Robot Inc](https://www.linkedin.com/company/hello-robot-inc/): Stretch AI, a set of open-source tools for language-guided autonomy, exploration, navigation, and learning from demonstration. The goal is to allow researchers and developers to quickly build and deploy AI-enabled robot applications.
 
Stretch AI is designed so that you can easily get started and try it out on your robot. It supports multiple LLMs, from open-source models like Qwen to OpenAI. You can even do voice control of the robot, talk to it, and have it clean up your floor!
 
The codebase: [https://lnkd.in/eyDU_3Hk](https://lnkd.in/eyDU_3Hk)  
Blog post with some details: [https://lnkd.in/eaSzMAtG](https://lnkd.in/eaSzMAtG)
   
\> From \<[https://www.linkedin.com/feed/](https://www.linkedin.com/feed/)\>   
**DROID setup:** [https://droid-dataset.github.io/droid/hardware-setup/shopping-list.html](https://droid-dataset.github.io/droid/hardware-setup/shopping-list.html)
 
Sapiens  
[https://about.meta.com/realitylabs/codecavatars/sapiens/](https://about.meta.com/realitylabs/codecavatars/sapiens/)
 
Open Devin: [https://arxiv.org/abs/2407.16741](https://arxiv.org/abs/2407.16741)
 
Open Source Rover:  
Open Source Rover 2.0 â€” which was designed entirely by the open-source community â€” addresses many pain points builders have encountered in the original concept, such as the electronics not being weatherproof, difficulty finding parts, and complexity with some of the build instructions. It also takes advantage of how technology has changed and how easy it is to outsource laser-cutting and 3D printing. One more bonus: the new model cuts the cost down to about $1,500.
 \> From \<[https://jpl.phenompro.com/blogarticle/5-things-to-know-about-the-jplfounded-open-source-rover-program](https://jpl.phenompro.com/blogarticle/5-things-to-know-about-the-jplfounded-open-source-rover-program)\>   
Can't GPU  
[https://github.com/nasa-jpl/open-source-rover?tab=readme-ov-file#ordering-parts](https://github.com/nasa-jpl/open-source-rover?tab=readme-ov-file#ordering-parts)
 
RAI - Flexible Agent Framework  
[https://github.com/RobotecAI/rai](https://github.com/RobotecAI/rai)
 
BiGym: [https://chernyadev.github.io/bigym/](https://chernyadev.github.io/bigym/)
 
[https://github.com/mbodiai/embodied-agents](https://github.com/mbodiai/embodied-agents)
 
ROBOCasa: [https://robocasa.ai/](https://robocasa.ai/)
 
Habitat 3.0: [https://ai.meta.com/research/publications/habitat-30-a-co-habitat-for-humans-avatars-and-robots/](https://ai.meta.com/research/publications/habitat-30-a-co-habitat-for-humans-avatars-and-robots/)
 
Assembly Planning: [http://asap.csail.mit.edu/](http://asap.csail.mit.edu/)
 
[https://simpler-env.github.io/](https://simpler-env.github.io/)
 
Droid: [https://droid-dataset.github.io/](https://droid-dataset.github.io/)
 
Project Gr00T: [https://nvidianews.nvidia.com/news/foundation-model-isaac-robotics-platform?ncid=so-link-762500-vt48](https://nvidianews.nvidia.com/news/foundation-model-isaac-robotics-platform?ncid=so-link-762500-vt48)  
[Donâ€™t Miss This Transformative Moment in AI](https://youtu.be/Y2F8yisiS6E?list=TLGGFIbdOwQMZx4xODAzMjAyNA&t=7633) - 2:13
 ![Embedded YouTube video](https://www.youtube.com/embed/Y2F8yisiS6E?start=7633&feature=oembed&autoplay=true)  

ROS2 + k8's: [https://github.com/fujitatomoya/ros_k8s/tree/master](https://github.com/fujitatomoya/ros_k8s/tree/master)
 
Turtlebot sim: **LLM testing virtually with turtlebots:** [https://turtlebot.github.io/turtlebot4-user-manual/tutorials/turtlebot4_navigator.html#large-language-model-integration](https://turtlebot.github.io/turtlebot4-user-manual/tutorials/turtlebot4_navigator.html#large-language-model-integration)
 
Aloha - Robot mobile Imitation learning: [https://mobile-aloha.github.io/](https://mobile-aloha.github.io/)  
Aloha2 [https://aloha-2.github.io/](https://aloha-2.github.io/)
 
Low cost hands: Dexterous Hands  
[http://www.dexhand.org/](http://www.dexhand.org/)
 
DexCap: [https://dex-cap.github.io/](https://dex-cap.github.io/)
 
**GAIA Generative AI Benchmark:** [https://huggingface.co/papers/2311.12983?utm_source=digest-papers&utm_medium=email&utm_campaign=2023-11-23](https://huggingface.co/papers/2311.12983?utm_source=digest-papers&utm_medium=email&utm_campaign=2023-11-23)
 
RL Library: **Pearl:** [https://github.com/facebookresearch/pearl](https://github.com/facebookresearch/pearl)
 
ROS Alternative? [https://github.com/dallison/adastra](https://github.com/dallison/adastra)
 
Benchmark for executable programs: [https://arxiv.org/pdf/2402.17553.pdf](https://arxiv.org/pdf/2402.17553.pdf)