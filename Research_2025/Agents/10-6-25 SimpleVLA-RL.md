Today, we're thrilled to highlight a groundbreaking new paper making waves in the robotics community, now featured on Hugging Face paper pages!
 
The research team at PRIME-Scaling has introduced SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning. This work addresses critical challenges in Vision-Language-Action (VLA) models, specifically the scarcity of large-scale human-operated robotic trajectories and limited generalization capabilities.
 
SimpleVLA-RL proposes an efficient reinforcement learning (RL) framework for VLA models. By building upon veRL and integrating VLA-specific trajectory sampling, scalable parallelization, and optimized loss computation, it dramatically improves long-horizon action planning.
 
The results are truly remarkable. SimpleVLA-RL achieves state-of-the-art performance on LIBERO, an 80% relative improvement on RoboTwin 1.0 & 2.0, and even a 120% relative improvement on real robots, outperforming advanced models like pi0 and RDT.
 
It also significantly reduces dependence on large-scale data, demonstrating robust generalization, and uncovers a novel "pushcut" phenomenon where the policy discovers previously unseen action patterns.
 
We're particularly excited that the authors have made their paper available on Hugging Face paper pages and their models in a dedicated collection. This commitment to open science and easy accessibility empowers the entire research community.
 
This is exactly the kind of open, reproducible research we love to see shared on Hugging Face Hub! We encourage more researchers to publish their papers and artifacts with us to maximize their impact.
 
Discover the full details and explore the models:
 
Paper: [https://lnkd.in/eHB_cwaG](https://lnkd.in/eHB_cwaG)  
Models: [https://lnkd.in/epbCKkip](https://lnkd.in/epbCKkip)  
Code: [https://lnkd.in/eP2aeV2n](https://lnkd.in/eP2aeV2n)
 \> From \<[https://www.linkedin.com/preload/](https://www.linkedin.com/preload/)\>