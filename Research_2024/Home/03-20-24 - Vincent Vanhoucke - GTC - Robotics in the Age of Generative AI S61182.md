Talk about the RT2 paper
 
LLMs as an understanding of the world
 
Embodied AI was supposed to be the next generation of AGI - fear of FOMO with LLM
 
LLM + Robotics -- biggest surprise on level of connections  
Deeper level reasoning about tasking/planning - wonderful and not great at the same time
 ![Exported image](Exported%20image%2020260222202740-0.png)      
SayCan discussion first - taking the planning peace of (perception - action -planning)  
RL on query for robot affordances
 ![Exported image](Exported%20image%2020260222202741-1.png)

Lift the planning aspect into the semantic world/space
 ![Exported image](Exported%20image%2020260222202743-2.png)  

"roll my eyes at perception - action -planning" - see Vanhouke blog
 
RT1 /2 = Next - replace perception with vision language models
 ![Exported image](Exported%20image%2020260222202744-3.png)  

Inner Monologue - A chat room inside the robot
 ![Exported image](Exported%20image%2020260222202746-4.png)   ![Exported image](Exported%20image%2020260222202748-5.png)  

Robots that ask for help - uncertainty alignment
 ![Exported image](Exported%20image%2020260222202752-6.png)  

AutoRT - Language Driven Exploration - can give high level concepts of safety and broad parameters to robot behavior
 ![Exported image](Exported%20image%2020260222202754-7.png)  

Code as Policies - however, hallucination proliferates until it understand what actual behaviors are wanted

![Exported image](Exported%20image%2020260222202756-8.png)  
![Exported image](Exported%20image%2020260222202757-9.png)  
![Exported image](Exported%20image%2020260222202759-10.png)  
![Exported image](Exported%20image%2020260222202800-11.png)  

Fundamental weakness - summarizing visual concepts in words can be convoluted - what if we tried to fuse them?
 
Palm-E - Perception and planning?
 ![Exported image](Exported%20image%2020260222202803-12.png)   ![Exported image](Exported%20image%2020260222202807-13.png)  
![Exported image](Exported%20image%2020260222202809-14.png)     
![Exported image](Exported%20image%2020260222202810-15.png)   
RT 1 - What if we Fuse Perception and Action?
 ![Exported image](Exported%20image%2020260222202811-16.png)  

Can separate performance on unseen tasks beyond behavior cloning

![Exported image](Exported%20image%2020260222202812-17.png)   
Data diversity is extremely important - multitask is not a subproblem - it is the problem
 ![Exported image](Exported%20image%2020260222202813-18.png)  

ï¿¼RT2? -Can we fuse perception, action, AND planning?
 ![Exported image](Exported%20image%2020260222202814-19.png)   
No robot data on Taylor Swift  
Emergent in the sense that all these things gel together in a unified way
 ![Exported image](Exported%20image%2020260222202820-20.png)  

Scaling - kind of problematic on inference speed/ scaling
 ![Exported image](Exported%20image%2020260222202821-21.png)   
Scaling across robots
 ![Exported image](Exported%20image%2020260222202823-22.png)  

Asked 34 institute to just dump the data together
 ![Exported image](Exported%20image%2020260222202824-23.png)   ![Exported image](Exported%20image%2020260222202825-24.png)  
![Exported image](Exported%20image%2020260222202826-25.png)  

"3 years ago I would've called you crazy if you showed me the following"
 
Completely greenfield new direction of robotics - ride the wave of genAI
 ![Exported image](Exported%20image%2020260222202828-26.png)   ![Exported image](Exported%20image%2020260222202832-27.png)