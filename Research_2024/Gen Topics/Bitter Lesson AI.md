[https://www.linkedin.com/posts/paulburchard_anthropics-dario-amodei-on-ais-limits-activity-7148414753793601536-mqdv?utm_source=share&utm_medium=member_desktop](https://www.linkedin.com/posts/paulburchard_anthropics-dario-amodei-on-ais-limits-activity-7148414753793601536-mqdv?utm_source=share&utm_medium=member_desktop)
 
The so-called “Bitter Lesson” of Artificial Intelligence is a popular fallacy that has been steadily diverting the entire field of artificial intelligence from its goals over the course of 7 decades, to devastating effect. It’s daunting to turn back such a tide, but let me try.
 
The essence of the fallacy is that due to the exponentially decreasing cost of compute due to Moore’s Law, and the exponentially falling cost and increasing availability of data due to the internet, brute force solutions to AI problems based on this scaling property will always beat any attempts to truly understand what intelligence is.
 
There are many deep flaws underlying this fallacy. A few key ones are:
 
1. Infeasibility of Brute Force.  
Many interesting AI problems are high dimensional, and the number of data points needed for a brute force solution goes up exponentially in dimension, quickly exceeding the number of atoms in the universe. So no practical results can actually be based on brute force, but must incorporate some kind of human ingenuity. Any claim to be using brute force is likely fraudulent.
 
2. Vast Undervaluation of Cost of Data.  
High quality data is now, and has always been, difficult and expensive to create. What has changed is that thanks to the internet, AI providers have been able to take, for fractions of a cent, products of human intelligence that cost their creators thousands of dollars of their time to create. These many orders of magnitude of undervaluation, even if legal, are incredibly short sighted, because they will kill off the creator economy that would be needed to supply any future training data.
 
3. Vastly Uneconomic Use of Compute.  
The human brain, running on 20 Watts, still beats out attempts at brute force AI algorithms, which require Megawatts to run, on problems where intelligence is truly needed.
 
4. Catastrophic Failure to Solve the Problem.  
Since as explained in point (1), attempts at brute force can actually only cover an exponentially small subset of possibilities, such brute force methods, having no actual intelligence of their own, will inevitably be asked to perform outside of their training data, at which point they will fail catastrophically. This might be amusing in a game, but not when applied to novel, high risk situations in real life when there is no training data to go on.
 
Although other original thinkers like [Rodney Brooks](https://www.linkedin.com/in/ACoAAANvbckBrsS3dgaKnQ1azM80keiQnhmTx68) have already argued against the so-called “Bitter Lesson”, such entreaties have so far not even slightly deterred the mainstream of AI from full commitment to this conceptual error (typical example below to show I'm not exaggerating). It is time for all the best minds in AI to start pushing back.