Imagine robots learning new skillsâ€”without any robot data.
 
Today, we're excited to release EgoZero: our first steps in training robot policies that operate in unseen environments, solely from data collected through humans wearing Aria smart glasses.
 
The key technical idea in EgoZero is to represent the scene as 3D points. This allows for:  
(a) Easy transfer of latent representation from human to robot.  
(b) Larger spatial (translation & rotation) generalization as we can easily data-augment for this.
 
For more details, check out our website: egozero-robot.github.io!
 
Preprint paper: [https://lnkd.in/gqTeNTiN](https://lnkd.in/gqTeNTiN)
 
This work was led by @vliu15 Ademi Adeniji & @david-zhan-96935126a and a wonderful collaboration with Raunaq Bhirangi & Pieter Abbeel
 \> From \<[https://www.linkedin.com/my-items/saved-posts/](https://www.linkedin.com/my-items/saved-posts/)\>