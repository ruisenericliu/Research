Detecting failures is critical to enabling trustworthy policy deployment in safety-critical settings. However, how do we detect policy failures during a rollout without a priori knowledge of potential failures?
 
We introduce FAIL-DetectðŸš¨, which requires no additional failure data and produces failure detectors that can distinguish successful versus failed rollouts in real time.
 
FAIL-Detect is a modular two-stage framework that (1) distills policy inputs and outputs into meaningful scalar signals and (2) constructs decision thresholds by leveraging conformal prediction bands. We further propose a novel flow-based density estimator to maximize the failure detection capability.
 
FAIL-Detect is task-agnostic and policy-agnostic to be highly flexible. Real-time detections are indicated with red borders below.
 
Website: [https://lnkd.in/dRAVeWf7](https://lnkd.in/dRAVeWf7)  
Paper: [https://lnkd.in/d9h9A_Sz](https://lnkd.in/d9h9A_Sz)  
Tweet: [https://lnkd.in/d6kQKTa9](https://lnkd.in/d6kQKTa9)
 
Truly honored and grateful to collaborate with Masha Itkina and Haruki Nishimura within the Trustworthy Learning under Uncertainty (TLU) team at Toyota Research Institute, where TLU strives for the safe and reliable deployment of learned robotic systems in real-world settings.
 
Big thanks to all other co-authors: Tony Khuong Nguyen, Emma Dixon, Christopher Rodriguez, Patrick "Tree" Miller, Robert Lee, Paarth Shah, RareÈ™ AmbruÈ™!
 \> From \<[https://www.linkedin.com/my-items/saved-posts/](https://www.linkedin.com/my-items/saved-posts/)\>