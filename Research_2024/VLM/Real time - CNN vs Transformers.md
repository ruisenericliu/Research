Better in fidelity (sometimes) but in production you want efficiency, ViTs are horrible for latency. CNNs are amazing and can easily match ViTs with the same training tricks (mask encodings, global response normaliztion etc ). LLMs are also not transformers as they were introduced in Vaswani et al. since BERT class mostly uses the encoder only while GPT only uses the decoder. Overall attention is just shit for real time. CNNs have a lot of advantages built into their architecture such as invariance to certain translations, equivariance and most importantly parameter sharing, then if you employ depthwise separable convolutions (depthwise + pointwise convolutions) you make them even more efficient. Stuff like these makes transformers really a huge no go for real time applications due to high latency and memory footprint.
 \> From \<[https://www.reddit.com/r/learnmachinelearning/comments/1d2qd35/so_we_can_all_agree_that_elon_musk_is_a_fraud/](https://www.reddit.com/r/learnmachinelearning/comments/1d2qd35/so_we_can_all_agree_that_elon_musk_is_a_fraud/)\>   
Unlikely, ViTs have pretty terrible on device latency and parameter efficiency compared to small-scale convnets. In general, ViTs smaller than the B model aren't all that great and their advantages really start to show once you get to L and larger but that's typically already too large for real-time applications on anything that's not a high-end GPU. The best models in that scale right now are the hybrid transformers that combine CNN and attention elements, and the most efficient one of those typically use much more convolutions than full linear layers.
 \> From \<[https://www.reddit.com/r/learnmachinelearning/comments/1d2qd35/so_we_can_all_agree_that_elon_musk_is_a_fraud/](https://www.reddit.com/r/learnmachinelearning/comments/1d2qd35/so_we_can_all_agree_that_elon_musk_is_a_fraud/)\>   
Extremely unlikely. FSD's compute capability is quite backwards in 2024 standards - only 73 Tops Int 8, 0.6 TFlops FP32, 8 GB of RAM, and ~64 GBps of memory bandwidth. My understanding is that although you can quantize Transforms into Int 8 weights, you will still need to convert them back into floating points when performing the actual calculation. So the 0.6 TFlops floating point capability basically means they can't run ViTs as vision backbones on FSDs. CNNs could be quantized with no problem and that's what they used as vision backbones according to their presentations. They do seem to use smaller transformers for trajectory planning though. I think LeCun understands this so he just dismantled Musk with words.  
Sources:  
[Tesla's CVPR '23 WAD Presentation](https://www.youtube.com/watch?v=6x-Xb_uT7ts)  
[FSD Chip Specs](https://en.wikichip.org/wiki/tesla_\(car_company\)/fsd_chip)