Excited to present my work on Canonical Similarity Analysis (CSA) at ICLR 2025, Singapore! ðŸš€
 
CSA enables data-efficient multimodal learning, requiring far less data than CLIP while achieving similar performance in image classification, cross-modal retrieval, and misinformative caption detection.
 
By leveraging pre-trained unimodal encoders, CSA maps features into a shared multimodal space via canonical correlation analysis (CCA), eliminating extensive GPU training. It supports LiDAR, audio, and time series, expanding multimodal learning beyond images and text.
 
CSA achieves 50,000x data efficiency over CLIP on ImageNet classification, making multimodal learning more accessible.
 
Huge thanks to my advisors [Ufuk Topcu](https://www.linkedin.com/in/ufuktopcu/) and [Sandeep Chinchali](https://www.linkedin.com/in/sandeep-chinchali/)!  
For more details:
 
1. Paper: [https://lnkd.in/gFWyQ7vT](https://lnkd.in/gFWyQ7vT)
 
2. Blog: [https://lnkd.in/gD7FYG57](https://lnkd.in/gD7FYG57)
 
3. Code: [https://lnkd.in/gVgJ6Rvh](https://lnkd.in/gVgJ6Rvh)
 \> From \<[https://www.linkedin.com/feed/update/urn:li:activity:7291224365591863296/](https://www.linkedin.com/feed/update/urn:li:activity:7291224365591863296/)\>