Fine-tuning NVIDIA's Gr00t 2B robotic model with only 0.5% of the parameters using PEFT. I wrote this during the Seeed Studio's Embedded AI hackathon. Not everyone has H200s - Robotic research on commodity GPUs!
 
[https://github.com/neil-tan/Isaac-GR00T/tree/569ff64499d61f307bd0c483be969e478c5657f0/scripts](https://github.com/neil-tan/Isaac-GR00T/tree/569ff64499d61f307bd0c483be969e478c5657f0/scripts)
   

ðŸš€ Thrilled to share that we won the Seeed EmbodiedAI Hackathon this weekend! It was an action-packed, learning-filled sprint where we pushed the limits of whatâ€™s possible with HuggingFace LeRobot and SO-100 Arms â€” fine-tuning Vision-Language-Action (VLA) models for pick/place and sorting tasks.ðŸ¤–ðŸ’¡
 
Even more exciting: we trained our own arm of NVIDIAâ€™s newly released GR00T N1 model, compared it against ACT and Pi0 and extended it to enable bimanual manipulation! ðŸ§ ðŸ¦¾ðŸ¦¾
 
ðŸ‘‰Huge shoutout to the dream team: Jason X., Chandravaran Kunjeti, Akshat Pandya, Nahid Alam, Anuj Agrawal, Vaibhav W.!
 
Checkout our project on Hackster.io:  
[https://lnkd.in/gCMxRXVs](https://lnkd.in/gCMxRXVs)
 
#Robotics #AI #Hackathon #VLA #NVIDIA #LeRobot #BimanualManipulation #GR00T #SeeedStudio #HuggingFace
 \> From \<[https://www.linkedin.com/my-items/saved-posts/](https://www.linkedin.com/my-items/saved-posts/)\>