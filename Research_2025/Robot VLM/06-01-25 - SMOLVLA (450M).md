ğŸš€ğ–ğ ğšğ«ğ ğ¢ğ§ğ­ğ«ğ¨ğğ®ğœğ¢ğ§ğ  ğ’ğ¦ğ¨ğ¥ğ•ğ‹ğ€-ğŸ’ğŸ“ğŸğŒ, ğšğ§ ğ¨ğ©ğğ§-ğ¬ğ¨ğ®ğ«ğœğ ğ•ğ¢ğ¬ğ¢ğ¨ğ§-ğ‹ğšğ§ğ ğ®ğšğ ğ-ğ€ğœğ­ğ¢ğ¨ğ§ ğ¦ğ¨ğğğ¥ ğŸğ¨ğ« ğ«ğ¨ğ›ğ¨ğ­ğ¢ğœğ¬!
 
SmolVLA achieves best-in-class performance and inference speed, and the best part? Itâ€™s trained entirely on open-source datasets from the ğŸ¤– LeRobot project hosted on the Hugging Face Hub.
 
ğŸ” Why is SmolVLA so good?
 
Turns out that pretraining on a large, diverse and noisy collection of real-world community robotics data leads to better generalization and control. We saw a 26% boost in task success rate simply from adding community dataset pretraining!
 
âš¡ Why is SmolVLA so fast?
 
1. We halved the size of SmolVLM and extract intermediate representations  
2. Introduced interleaved cross- and self-attention layers in the action expert  
3. Enabled asynchronous inference so the robot acts and reacts simultaneously
 
ğŸ’¡ Unlike most academic datasets, these community-contributed datasets are naturally diverse:  
âœ… Multiple robots, camera angles, and manipulation tasks  
âœ… Real-world messiness and complexity  
âœ… Crowd-sourced and community-cleaned using Qwen2.5-VL for high-quality task descriptions
 
ğŸŒ SmolVLA is a step toward making robotics research more affordable, reproducible, and collaborative.
 
ğŸ“– Want to dive deeper? Check out our blog post & start using it today: [https://lnkd.in/e3Gmy8gT](https://lnkd.in/e3Gmy8gT)
 
Huge thanks to the team who made this possible: @Mustafa Shukor Francesco Capuano Remi Cadene, and the entire Lerobot team, amazing HF team AndrÃ©s Marafioti Merve Noyan Aritra Roy Gosthipaty Pedro Cuenca Loubna Ben Allal, Thomas Wolf and to the amazing contributors to the LeRobot community: Ville Kuosmanen, Alexandre Chapin, Marina Barannikov, and more!