Let's build a multi-agent internet research assistant using OpenAI Swarm & Llama 3.2 (100% local)!
 
The app takes a user query, searches the web for it, and turns it into a well-crafted article.
 
Here's what you'll learn:
 
- [Ollama](https://www.linkedin.com/company/ollama/) for running LLMs locally  
- [OpenAI](https://www.linkedin.com/company/openai/) Swarm for multi-agent orchestration  
- [Streamlit](https://www.linkedin.com/company/streamlit/) for the UI
 
Let's go! ðŸš€
 
Key component:
 
1ï¸âƒ£ Agent 1: Web search and tool use
 
The web-search agent takes a user query and then use the DuckDuckGo search tool to fetch results from internet.
 
2ï¸âƒ£ Agent 2: Research Analyst
 
The role of this agent is to analyse and curate the raw search results and make them ready to use for the content writer agent.
 
3ï¸âƒ£ Agent 3: Technical Writer
 
The role of technical writer is to use the curated results and turn them into a polished, publication-ready article .
 
4ï¸âƒ£ The Chat interface
 
Finally we create a Streamlit UI to provide a chat interface for our application.  
____  
Find all the code in this GitHub repo: [https://lnkd.in/gMTZDvR9](https://lnkd.in/gMTZDvR9)  
____
 \> From \<[https://www.linkedin.com/feed/](https://www.linkedin.com/feed/)\>     

This came unexpected! [OpenAI](https://www.linkedin.com/company/openai/) released Swarm, a lightweight library for building multi-agent systems. Swarm provides a stateless abstraction to manage interactions and handoffs between multiple agents and does not use the Assistants API. ðŸ‘€
 
How it works:  
1ï¸âƒ£ Define Agents, each with its own instructions, role (e.g., "Sales Agent"), and available functions (will be converted to JSON structures).  
2ï¸âƒ£ Define logic for transferring control to another agent based on conversation flow or specific criteria within agent functions. This handoff is achieved by simply returning the next agent to call within the function.  
3ï¸âƒ£ Context Variables provide initial context and update them throughout the conversation to maintain state and share information between agents.  
4ï¸âƒ£ [Client.run](http://Client.run)() initiate and manage the multi-agent conversation. Needs initial agent, user messages, and context and returns a response containing updated messages, context variables, and the last active agent.
 
Insights  
ðŸ”„ Swarm manages a loop of agent interactions, function calls, and potential handoffs.  
ðŸ§© Agents encapsulate instructions, available functions (tools), and handoff logic.  
ðŸ”Œ The framework is stateless between calls, offering transparency and fine-grained control.  
ðŸ› ï¸ Swarm supports direct Python function calling within agents.  
ðŸ“Š Context variables enable state management across agent interactions.  
ðŸ”„ Agent handoffs allow for dynamic switching between specialized agents.  
ðŸ“¡ Streaming responses are supported for real-time interaction.  
ðŸ§ª The framework is experimental. Maybe to collect feedback?  
ðŸ”§ Flexible and works with any OpenAI client, e.g. Hugging Face TGI or vLLM hosted models.
 
Repository: [https://lnkd.in/eWKMBkqU](https://lnkd.in/eWKMBkqU)
 \> From \<[https://www.linkedin.com/feed/](https://www.linkedin.com/feed/)\>