ROLO-SLAM [1]: Rotation-Optimized LiDAR-Only SLAM in Uneven Terrain with Ground Vehicle. It is a lightweight and robust LiDAR-based SLAM solution designed to improve the accuracy of pose estimation for ground vehicles in rough terrains. It incorporates several algorithmic innovations that reduce pose estimation drifts, particularly in the vertical direction, which are commonly observed when navigating uneven terrains. The method includes forward location prediction to coarsely eliminate the location differences between consecutive scans, enabling separate and accurate localization and orientation determination. Additionally, ROLO-SLAM features a parallel-capable spatial voxelization for correspondence matching, along with a spherical alignment-guided rotation registration to estimate vehicle rotation. By incorporating motion constraints into the optimization process, the algorithm enhances the rapid and effective estimation of LiDAR translation. Extensive experiments conducted across diverse environments demonstrate that ROLO-SLAM consistently achieves accurate pose estimation and outperforms existing state-of-the-art LiDAR SLAM solutions, making it a reliable choice for ground vehicle localization in perceptually-challenging environments.
 
ROLO requires an input point cloud of type sensor_msgs::PointCloud2 . ROLO-SLAM mitigates vertical pose drift by dividing the front-end into three modules: forward location prediction for coarse translation estimation, voxelization matching for precise rotation estimation, and continuous-time translation estimation for improved accuracy. The back-end integrates scan-to-submap alignment and global factor graph optimization to enhance overall localization performance in challenging terrains.
 
[hashtag#ros](https://www.linkedin.com/feed/hashtag/?keywords=ros&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#ros2](https://www.linkedin.com/feed/hashtag/?keywords=ros2&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#opensource](https://www.linkedin.com/feed/hashtag/?keywords=opensource&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#robot](https://www.linkedin.com/feed/hashtag/?keywords=robot&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#robotics](https://www.linkedin.com/feed/hashtag/?keywords=robotics&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#lidar](https://www.linkedin.com/feed/hashtag/?keywords=lidar&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#odometry](https://www.linkedin.com/feed/hashtag/?keywords=odometry&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#slam](https://www.linkedin.com/feed/hashtag/?keywords=slam&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#groundvehicle](https://www.linkedin.com/feed/hashtag/?keywords=groundvehicle&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#lightweight](https://www.linkedin.com/feed/hashtag/?keywords=lightweight&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#robust](https://www.linkedin.com/feed/hashtag/?keywords=robust&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245) [hashtag#navigation](https://www.linkedin.com/feed/hashtag/?keywords=navigation&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7304871203909898245)
 
[1] [https://lnkd.in/dE7x4AuS](https://lnkd.in/dE7x4AuS)
 \> From \<[https://www.linkedin.com/feed/update/urn:li:activity:7304871203909898245/](https://www.linkedin.com/feed/update/urn:li:activity:7304871203909898245/)\>