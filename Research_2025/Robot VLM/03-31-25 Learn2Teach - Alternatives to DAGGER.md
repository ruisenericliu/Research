ðŸš€ Can we do even better than DAGGER (a popular imitation learning algorithm in RL) in terms of sample efficiency? Absolutely!
 
Check out our latest work on Learn to Teach (L2T)â€”a one-stage training framework that seamlessly unifies teacher and student policy learning. This work is led by our ML Ph.D. student Feiyang Wu and his excellent team Xavier Nal Jaehwi Jang Wei Zhu and Zhaoyuan Gu. By recycling simulator samples and synchronizing learning trajectories through shared dynamics, L2T slashes sample complexity and training time while achieving the SOTA performance.
 
But we didnâ€™t stop there. We put L2T to the test with extensive simulations and hardware trials on our Digit robot, proving its zero-shot sim-to-real transfer across 12+ tough terrainsâ€”all without depth estimation modules. The result? Unmatched robustness and adaptability in real-world scenarios.  
If you're into RL for robotics, this is one you donâ€™t want to miss! ðŸš€ðŸ¤– George W. Woodruff School of Mechanical Engineering Georgia Tech Research Georgia Tech College of Engineering Georgia Tech School of Computational Science and Engineering
 
[https://lnkd.in/eAtgRTqB](https://lnkd.in/eAtgRTqB)  
[https://lnkd.in/eYxRQmUW](https://lnkd.in/eYxRQmUW)  
[https://lnkd.in/e_6J-D8b](https://lnkd.in/e_6J-D8b) (full video)
 
#ReinforcementLearning #AI #Robotics #MachineLearning #SimToReal #RL
 \> From \<[https://www.linkedin.com/my-items/saved-posts/](https://www.linkedin.com/my-items/saved-posts/)\>