7/07/25 Meta Embodied AI Agents  
[https://arxiv.org/abs/2506.22355](https://arxiv.org/abs/2506.22355)
 
This paper describes our research on AI agents embodied in visual, virtual or physical forms, enabling them to interact with both users and their environments. These agents, which include virtual avatars, wearable devices, and robots, are designed to perceive, learn and act within their surroundings, which makes them more similar to how humans learn and interact with the environments as compared to disembodied agents. We propose that the development of world models is central to reasoning and planning of embodied AI agents, allowing these agents to understand and predict their environment, to understand user intentions and social contexts, thereby enhancing their ability to perform complex tasks autonomously. World modeling encompasses the integration of multimodal perception, planning through reasoning for action and control, and memory to create a comprehensive understanding of the physical world. Beyond the physical world, we also propose to learn the mental world model of users to enable better human-agent collaboration.
   

Fine-Tuning V-JEPA(2)
 
‚èØÔ∏è video fine-tuning support for Meta's V-JEPA 2 in Hugging Face transformers is just in üî•
 
it comes with:  
\> fine-tuning script & notebook  
\> four models fine-tuned on Diving48 and SSv2 dataset  
\> FastRTC demo on V-JEPA2 SSv2 (see below)
 
we're looking forward to see more fine-tuned V-JEPA 2 models on Hugging Face Hub ü§ó links are in comments ü§ù
 
V-JEPA2: [https://ai.meta.com/vjepa/](https://ai.meta.com/vjepa/)
   

I-JEPA: [https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/](https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/)  
[https://openreview.net/pdf?id=BZ5a1r-kVsf](https://openreview.net/pdf?id=BZ5a1r-kVsf)  
[https://arxiv.org/abs/2301.08243?ref=ghost.oxen.ai](https://arxiv.org/abs/2301.08243?ref=ghost.oxen.ai)
 
V-JEPA: [https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/](https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/)  
[V-JEPA: Revisiting Feature Prediction for Learning Visual Representations from Video (Explained)](https://www.youtube.com/watch?v=7UkJPwz_N_0)  
[https://openreview.net/forum?id=WFYbBOEOtv](https://openreview.net/forum?id=WFYbBOEOtv)
 
IWM: [https://arxiv.org/abs/2403.00504](https://arxiv.org/abs/2403.00504)